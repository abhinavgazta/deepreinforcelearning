{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0505a39-0c51-457f-ab8a-128a3ba56dac",
   "metadata": {},
   "source": [
    "<h1>Distributed Hyperparameter Optimization (HPO) Techniques for CNN on MNIST</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28eb5993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.17.2)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.2.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torchvision) (2.2.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch==2.2.2->torchvision) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch==2.2.2->torchvision) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch==2.2.2->torchvision) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch==2.2.2->torchvision) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch==2.2.2->torchvision) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch==2.2.2->torchvision) (2025.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch==2.2.2->torchvision) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy->torch==2.2.2->torchvision) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: optuna in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.2.1)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from optuna) (1.15.1)\n",
      "Requirement already satisfied: colorlog in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from optuna) (24.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from optuna) (2.0.39)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in /Users/abhinav.gazta/Library/Python/3.11/lib/python/site-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: Mako in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from alembic>=1.5.0->optuna) (1.3.9)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: hpbandster in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.7.4)\n",
      "Requirement already satisfied: Pyro4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from hpbandster) (4.82)\n",
      "Requirement already satisfied: serpent in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from hpbandster) (1.41)\n",
      "Requirement already satisfied: ConfigSpace in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from hpbandster) (1.2.1)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from hpbandster) (1.26.4)\n",
      "Requirement already satisfied: statsmodels in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from hpbandster) (0.14.4)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from hpbandster) (1.15.2)\n",
      "Requirement already satisfied: netifaces in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from hpbandster) (0.11.0)\n",
      "Requirement already satisfied: pyparsing in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ConfigSpace->hpbandster) (3.2.1)\n",
      "Requirement already satisfied: typing_extensions in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ConfigSpace->hpbandster) (4.12.2)\n",
      "Requirement already satisfied: more_itertools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ConfigSpace->hpbandster) (10.6.0)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from statsmodels->hpbandster) (2.2.3)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from statsmodels->hpbandster) (1.0.1)\n",
      "Requirement already satisfied: packaging>=21.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from statsmodels->hpbandster) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ConfigSpace in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.2.1)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ConfigSpace) (1.26.4)\n",
      "Requirement already satisfied: pyparsing in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ConfigSpace) (3.2.1)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ConfigSpace) (1.15.2)\n",
      "Requirement already satisfied: typing_extensions in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ConfigSpace) (4.12.2)\n",
      "Requirement already satisfied: more_itertools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ConfigSpace) (10.6.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchsummary in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.5.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: plotly in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (6.0.1)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from plotly) (1.31.0)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from plotly) (24.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# TO BE DELETED ONCE COMPLETE\n",
    "%pip install torchvision\n",
    "%pip install optuna\n",
    "%pip install hpbandster\n",
    "%pip install ConfigSpace\n",
    "%pip install torch\n",
    "%pip install torchsummary\n",
    "%pip install plotly\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40378dfd-c7b5-4245-a20b-27c4024d8854",
   "metadata": {},
   "source": [
    "<h2>1. Introduction</h2>\n",
    "\n",
    "Hyperparameter Optimization (HPO) is a critical step in deep learning model training to improve accuracy and efficiency. \n",
    "Traditional hyperparameter tuning approaches like Grid Search and Random Search are computationally expensive and inefficient. \n",
    "\n",
    "In this assignment, we compare and analyze different hyperparameter optimization strategies using distributed computing to achieve optimal hyperparameter selection efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06f8c43-f571-4fa8-9035-b4872b8a1a31",
   "metadata": {},
   "source": [
    "<h2>2. Objectives</h2>\n",
    "\n",
    "The goal of this project is to:\n",
    "\n",
    "1. Compare multiple HPO techniques for training a Convolutional Neural Network (CNN) on the MNIST dataset.\n",
    "\n",
    "2. Evaluate these techniques based on training speed, search efficiency, accuracy, and GPU resource utilization.\n",
    "\n",
    "3. Implement real-time GPU monitoring to track memory usage and optimize resource allocation.\n",
    "\n",
    "4. Identify the most effective HPO method that balances speed, accuracy, and efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f276fa1-ccda-4598-8a80-742c5c02154f",
   "metadata": {},
   "source": [
    "<h2>3. HPO Strategies Implemented</h2>\n",
    "\n",
    "We implemented and compared four different approaches for HPO:\n",
    "\n",
    "1. Baseline (No HPO): Train the model with default hyperparameters.\n",
    "\n",
    "2. ASHA (Asynchronous Successive Halving Algorithm): Eliminates underperforming trials early to speed up training.\n",
    "\n",
    "3. BOHB (Bayesian Optimization + HyperBand): Uses Bayesian learning to intelligently select hyperparameters while efficiently allocating compute resources.\n",
    "\n",
    "4. BOHB + ASHA Hybrid: Combines BOHB’s smart selection with ASHA’s aggressive pruning for improved efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20a9552-e528-44b8-84da-76ad306fd4c8",
   "metadata": {},
   "source": [
    "<h2>4. Implementation Details</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1af501-d51b-40a7-828d-a80e561c4a49",
   "metadata": {},
   "source": [
    "<h2>4.1 Dataset: MNIST</h2>\n",
    "\n",
    "The MNIST dataset consists of handwritten digits (0-9).\n",
    "\n",
    "Training set: 1000 images.\n",
    "\n",
    "Test set: 1000 images.\n",
    "\n",
    "Image size: 28x28 pixels, grayscale.\n",
    "\n",
    "Output classes: 10 (digits 0-9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c712bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 12:05:33.722277: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "import optuna\n",
    "from optuna.pruners import SuccessiveHalvingPruner\n",
    "\n",
    "import hpbandster.core.nameserver as hpns\n",
    "import hpbandster.core.result as hpres\n",
    "from hpbandster.optimizers.bohb import BOHB\n",
    "from hpbandster.core.worker import Worker\n",
    "import ConfigSpace as CS\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import ssl\n",
    "import time\n",
    "import psutil\n",
    "import random\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9c1806f-471a-46b3-bc51-4c009c826047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:02<00:00, 4484191.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 143461.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:01<00:00, 1479402.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 4570664.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load full MNIST dataset\n",
    "full_trainset = torchvision.datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "full_testset = torchvision.datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "# Select 1000 random indices for train and test sets\n",
    "train_indices = np.random.choice(len(full_trainset), 10000, replace=False)\n",
    "test_indices = np.random.choice(len(full_testset), 10000, replace=False)\n",
    "\n",
    "# Create subsets of MNIST\n",
    "trainset = Subset(full_trainset, train_indices)\n",
    "testset = Subset(full_testset, test_indices)\n",
    "\n",
    "# Create DataLoaders\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "dataset = (trainloader, testloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac9196b-0d2d-43cd-85fe-4a1a4ba4aa7f",
   "metadata": {},
   "source": [
    "<h2>4.2 Model: CNN Architecture</h2>\n",
    "\n",
    "The CNN model used for training consists of:\n",
    "\n",
    "1. Two convolutional layers with ReLU activation.\n",
    "\n",
    "2. Max-pooling layers for feature down-sampling.\n",
    "\n",
    "3. Fully connected layers with a dropout layer.\n",
    "\n",
    "4. Softmax activation for classification.\n",
    "\n",
    "<b>Hyperparameters Considered</b>\n",
    "\n",
    "Learning Rate - 1e-4 to 1e-2 (log scale)\n",
    "\n",
    "Dropout Rate - 0.2 to 0.5\n",
    "\n",
    "Number of Filters - 16, 32, 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ddb55b1-1211-487b-878a-cafaef7b7b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# CNN Model for MNIST\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, dropout_rate=0.5, num_filters=32):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, num_filters, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(num_filters, num_filters * 2, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(num_filters * 2 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabadb6d-8c84-44e4-a84f-0f29d235a66e",
   "metadata": {},
   "source": [
    "<h2>4.3 GPU Monitoring & Resource Utilization Tracking</h2>\n",
    "\n",
    "We implemented real-time GPU monitoring using PyTorch’s memory allocation tracking.\n",
    "\n",
    "GPU usage was recorded at each training epoch.\n",
    "\n",
    "This allowed us to compare memory efficiency across different HPO techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f23cea0c-590e-4a5e-8742-dc0766bc902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to log memory usage (CPU + GPU approximation)\n",
    "def log_memory_usage(stage=\"\"):\n",
    "    # Get CPU RAM usage\n",
    "    ram_usage = psutil.virtual_memory().used / (1024 ** 2)  # Convert to MB\n",
    "    \n",
    "    # Get GPU memory (Approximate via tensor usage)\n",
    "    if device.type == \"mps\":\n",
    "        torch.mps.empty_cache()  # Free unused memory (for better tracking)\n",
    "        gpu_usage = \"MPS does not expose memory tracking\"\n",
    "    else:\n",
    "        gpu_usage = \"GPU not in use\"\n",
    "    \n",
    "    return ram_usage, gpu_usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3034e26-fe0d-454d-afb6-fe1023814bb7",
   "metadata": {},
   "source": [
    "<h2>5. Comparison of HPO Approaches</h2>\n",
    "\n",
    "1. Training Speed\n",
    "2. Model Accuracy\n",
    "3. GPU Memory Utilization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e5b13a-4008-4923-863e-9a3beaba337c",
   "metadata": {},
   "source": [
    "<h2>5.1 Baseline Model (No HPO)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c14589a-da69-4c1d-92c5-6e2f2e515221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7400a6d-ddfa-45db-b214-ce6d0d6d13d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Baseline Accuracy: 98.24%, Training Time: 38.88s, Avg CPU RAM Usage: 8611.47 MB, GPU Usage: MPS does not expose memory tracking\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Train Baseline Model (Without HPO) with GPU Logging\n",
    "def train_baseline():\n",
    "    writer = SummaryWriter(log_dir=\"./logs/baseline\")\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    model = CNN().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # gpu_usages = []\n",
    "    memory_logs = []\n",
    "\n",
    "    for epoch in range(5):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        # Log GPU Memory\n",
    "        # gpu_usage = log_gpu_usage(\"Baseline\")\n",
    "        # gpu_usages.append(gpu_usage)\n",
    "        \n",
    "        # Log Memory Usage\n",
    "        ram_usage, gpu_usage = log_memory_usage(\"Baseline\")\n",
    "        memory_logs.append(ram_usage)\n",
    "        \n",
    "        writer.add_scalar(\"Loss/train\", epoch_loss / len(trainloader), epoch)\n",
    "        writer.add_scalar(\"Memory/CPU_RAM_MB\", ram_usage, epoch)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Compute GPU Usage Stats\n",
    "    # avg_gpu_usage = sum(gpu_usages) / len(gpu_usages)\n",
    "    # avg_gpu_usage = \"MPS memory tracking unavailable\"\n",
    "\n",
    "    # Compute Average Memory Usage\n",
    "    avg_ram_usage = sum(memory_logs) / len(memory_logs)\n",
    "\n",
    "    # Test Model\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Baseline Accuracy: {accuracy:.2f}%, Training Time: {end_time - start_time:.2f}s, Avg CPU RAM Usage: {avg_ram_usage:.2f} MB, GPU Usage: {gpu_usage}\")\n",
    "    writer.close()\n",
    "\n",
    "    # return accuracy, end_time - start_time, avg_gpu_usage\n",
    "    return accuracy, end_time - start_time, avg_ram_usage\n",
    "    \n",
    "\n",
    "# Run Baseline Training\n",
    "# baseline_accuracy, baseline_time, baseline_gpu = train_baseline()\n",
    "baseline_accuracy, baseline_time, baseline_memory = train_baseline()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76ca153-a9fa-4683-80c0-b9f59093fdc0",
   "metadata": {},
   "source": [
    "<h2>5.2 ASHA HPO</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c101f417-fab2-4a62-ad18-ff0b728ac423",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Train Model with ASHA HPO, Memory Logging, and TensorBoard Logging\n",
    "def train_cnn_asha(trial):\n",
    "    writer = SummaryWriter(log_dir=f\"./logs/asha_trial_{trial.number}\")  # TensorBoard log directory\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "    # Sample hyperparameters using Optuna\n",
    "    dropout_rate = trial.suggest_float(\"dropout\", 0.2, 0.5)\n",
    "    num_filters = trial.suggest_categorical(\"num_filters\", [16, 32, 64])\n",
    "    learning_rate = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "\n",
    "    model = CNN(dropout_rate=dropout_rate, num_filters=num_filters).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    memory_logs = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(5):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        # Log Memory Usage\n",
    "        ram_usage, gpu_usage = log_memory_usage(\"ASHA\")\n",
    "        memory_logs.append(ram_usage)\n",
    "\n",
    "        # Log Loss and Memory to TensorBoard\n",
    "        writer.add_scalar(\"Loss/train\", epoch_loss / len(trainloader), epoch)\n",
    "        writer.add_scalar(\"Memory/CPU_RAM_MB\", ram_usage, epoch)\n",
    "\n",
    "        # Evaluate Model (ASHA needs validation accuracy for pruning)\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in testloader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "\n",
    "        # Report accuracy for ASHA pruning\n",
    "        trial.report(accuracy, epoch)\n",
    "\n",
    "        # ASHA: Stop bad trials early\n",
    "        if trial.should_prune():\n",
    "            writer.close()  # Ensure writer closes even when pruned\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Compute Average CPU Memory Usage\n",
    "    avg_ram_usage = sum(memory_logs) / len(memory_logs)\n",
    "\n",
    "    # Log final accuracy and memory stats to TensorBoard\n",
    "    writer.add_scalar(\"Accuracy\", accuracy)\n",
    "    writer.add_scalar(\"Training Time (s)\", end_time - start_time)\n",
    "    writer.close()\n",
    "\n",
    "    # Print Summary (Same Format as Baseline)\n",
    "    print(f\"Accuracy: {accuracy:.2f}%, Training Time: {end_time - start_time:.2f}s, \"\n",
    "          f\"Avg CPU RAM Usage: {avg_ram_usage:.2f} MB, GPU Usage: {gpu_usage}\")\n",
    "\n",
    "    return accuracy, end_time - start_time, avg_ram_usage, gpu_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33ee6251-1944-46b2-ac6e-2bb314f192d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/_experimental.py:31: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "[I 2025-03-18 12:15:15,782] A new study created in memory with name: asha_hpo\n",
      "[I 2025-03-18 12:16:16,141] Trial 0 finished with value: 97.66 and parameters: {'dropout': 0.39120732202654807, 'num_filters': 64, 'lr': 0.00029045640929732837}. Best is trial 0 with value: 97.66.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.66%, Training Time: 59.36s, Avg CPU RAM Usage: 8869.64 MB, GPU Usage: MPS does not expose memory tracking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-18 12:17:10,045] Trial 1 finished with value: 98.23 and parameters: {'dropout': 0.4177646823620649, 'num_filters': 64, 'lr': 0.0010718539614060052}. Best is trial 1 with value: 98.23.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.23%, Training Time: 53.88s, Avg CPU RAM Usage: 8396.55 MB, GPU Usage: MPS does not expose memory tracking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-18 12:18:01,179] Trial 2 pruned. \n",
      "[I 2025-03-18 12:18:24,295] Trial 3 pruned. \n",
      "[I 2025-03-18 12:18:52,496] Trial 4 pruned. \n",
      "[I 2025-03-18 12:19:20,421] Trial 5 pruned. \n",
      "[I 2025-03-18 12:19:40,054] Trial 6 pruned. \n",
      "[I 2025-03-18 12:20:00,200] Trial 7 pruned. \n",
      "[I 2025-03-18 12:20:20,191] Trial 8 pruned. \n",
      "[I 2025-03-18 12:20:39,689] Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model Config: {'dropout': 0.4177646823620649, 'num_filters': 64, 'lr': 0.0010718539614060052}\n",
      "Best Accuracy: 98.23%\n",
      "Best Training Time: 53.88s\n",
      "Best Avg CPU RAM Usage: 8396.55 MB\n",
      "Best GPU Usage: MPS does not expose memory tracking\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.pruners import SuccessiveHalvingPruner\n",
    "import multiprocessing\n",
    "\n",
    "# Store best training time & resource usage\n",
    "best_training_time = float(\"inf\")\n",
    "best_ram_usage = float(\"inf\")\n",
    "best_gpu_usage = None\n",
    "\n",
    "# Optimize parallel processing\n",
    "# n_jobs = max(1, multiprocessing.cpu_count() // 2)  # Use half the available cores\n",
    "\n",
    "# Enable best GPU performance for Apple MPS\n",
    "torch.set_float32_matmul_precision('high') \n",
    "\n",
    "# Define Objective Function for Optuna\n",
    "def objective(trial):\n",
    "    global best_training_time, best_ram_usage, best_gpu_usage\n",
    "\n",
    "    accuracy, training_time, avg_ram_usage, gpu_usage = train_cnn_asha(trial)  # Now returns more metrics\n",
    "\n",
    "    # Track best training time & resource utilization\n",
    "    if training_time < best_training_time:\n",
    "        best_training_time = training_time\n",
    "        best_ram_usage = avg_ram_usage\n",
    "        best_gpu_usage = gpu_usage\n",
    "\n",
    "    return accuracy  # Optuna optimizes based on accuracy\n",
    "\n",
    "# Create Optuna Study with ASHA (Successive Halving)\n",
    "study = optuna.create_study(\n",
    "    study_name=\"asha_hpo\",\n",
    "    direction=\"maximize\",  # We want to maximize accuracy\n",
    "    pruner=SuccessiveHalvingPruner(),  # ASHA Pruning\n",
    "    sampler=optuna.samplers.TPESampler(\n",
    "        multivariate=True,  # Optimizes multiple parameters together\n",
    "        constant_liar=True  # Avoids redundant evaluations\n",
    "    )\n",
    ")\n",
    "\n",
    "# Run Optimization (20 Trials)\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# Print Best Results\n",
    "print(f\"\\nBest Model Config: {study.best_params}\")\n",
    "print(f\"Best Accuracy: {study.best_value:.2f}%\")\n",
    "print(f\"Best Training Time: {best_training_time:.2f}s\")\n",
    "print(f\"Best Avg CPU RAM Usage: {best_ram_usage:.2f} MB\")\n",
    "print(f\"Best GPU Usage: {best_gpu_usage}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75d08002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (6.0.1)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from plotly) (1.31.0)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from plotly) (24.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "560b8f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'study' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moptuna\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvisualization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m plot_optimization_history, plot_param_importances\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Plot optimization history\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m optimization_history_fig = plot_optimization_history(\u001b[43mstudy\u001b[49m)\n\u001b[32m      6\u001b[39m optimization_history_fig.show()\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Plot parameter importances\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'study' is not defined"
     ]
    }
   ],
   "source": [
    "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
    "\n",
    "\n",
    "# Plot optimization history\n",
    "optimization_history_fig = plot_optimization_history(study)\n",
    "optimization_history_fig.show()\n",
    "\n",
    "# Plot parameter importances\n",
    "param_importances_fig = plot_param_importances(study)\n",
    "param_importances_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3c1dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f8056fc-b5af-4ecf-b9aa-72db7d07e700",
   "metadata": {},
   "source": [
    "<h2>5.3 Train with BOHB HPO</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c54e3435-9bd7-4d3a-aa9f-273b68001603",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define Worker for BOHB\n",
    "class CNNWorker(Worker):\n",
    "    def __init__(self, run_id, dataset, **kwargs):\n",
    "        # print('__init__')\n",
    "        super().__init__(run_id, **kwargs)\n",
    "        self.trainloader, self.testloader = dataset\n",
    "        self.device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "    def compute(self, config, budget, **kwargs):\n",
    "        print(type(config))\n",
    "        print(type(budget))\n",
    "        writer = SummaryWriter(log_dir=f\"./logs/bohb_trial_{config}\")\n",
    "        print('writer')\n",
    "\n",
    "        # ✅ Convert `config` to Python native dict\n",
    "        config_native = {key: int(value) if isinstance(value, np.integer) else float(value) if isinstance(value, np.floating) else value for key, value in config.items()}\n",
    "        \n",
    "        model = CNN(dropout_rate=float(config[\"dropout\"]), num_filters=int(config[\"num_filters\"])).to(self.device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=float(config[\"lr\"]))\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        print('reached loss_fn')\n",
    "\n",
    "        memory_logs = []\n",
    "        start_time = time.time()\n",
    "\n",
    "        for epoch in range(int(budget)):  # `budget` is set by BOHB (early stopping)\n",
    "            model.train()\n",
    "            epoch_loss = 0\n",
    "            for images, labels in self.trainloader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "            # Log Memory Usage\n",
    "            ram_usage, gpu_usage = log_memory_usage()\n",
    "            memory_logs.append(float(ram_usage))\n",
    "\n",
    "            # Log Loss and Memory to TensorBoard\n",
    "            writer.add_scalar(\"Loss/train\", epoch_loss / len(self.trainloader), epoch)\n",
    "            writer.add_scalar(\"Memory/CPU_RAM_MB\", ram_usage, epoch)\n",
    "\n",
    "        end_time = time.time()\n",
    "        avg_ram_usage = sum(memory_logs) / len(memory_logs)\n",
    "\n",
    "        # Evaluate Model\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in self.testloader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "\n",
    "        # ✅ Convert all NumPy types to standard Python types before returning\n",
    "        accuracy = int(np.round(accuracy))  # Convert NumPy int64 to Python int\n",
    "        avg_ram_usage = float(np.round(avg_ram_usage, 2))  # Convert float32 to Python float\n",
    "        training_time = float(np.round(end_time - start_time, 2))  # Convert time to Python float\n",
    "\n",
    "        writer.add_scalar(\"Accuracy\", accuracy)\n",
    "        writer.add_scalar(\"Training Time (s)\", training_time)\n",
    "        writer.close()\n",
    "\n",
    "        print(f\"Accuracy: {accuracy:.2f}%, Training Time: {training_time:.2f}s, \"\n",
    "              f\"Avg CPU RAM Usage: {avg_ram_usage:.2f} MB, GPU Usage: {gpu_usage}\")\n",
    "\n",
    "        return {\n",
    "        \"loss\": -accuracy,  # Loss should be negative for BOHB to maximize accuracy\n",
    "        \"info\": {\n",
    "            \"training_time\": training_time,\n",
    "            \"ram_usage\": avg_ram_usage,\n",
    "            \"config\": config_native  # ✅ Ensure all values are JSON serializable\n",
    "            }\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def get_configspace():\n",
    "        cs = CS.ConfigurationSpace()\n",
    "        cs.add(CS.UniformFloatHyperparameter(\"dropout\", lower= float(0.2), upper= float(0.5)))\n",
    "        cs.add(CS.CategoricalHyperparameter(\"num_filters\", choices=[16, 32, 64]))\n",
    "        cs.add(CS.UniformFloatHyperparameter(\"lr\", lower=float(0.0001), upper=float(0.01)))\n",
    "        # print('CS')\n",
    "        return cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "505516ff-3c9d-4b15-a816-e0b0359a4e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_configspace():\n",
    "    config_space = {\n",
    "        \"dropout\": {\"type\": \"float\", \"lower\": 0.2, \"upper\": 0.5},\n",
    "        \"num_filters\": {\"type\": \"categorical\", \"choices\": [16, 32, 64]},\n",
    "        \"lr\": {\"type\": \"float\", \"lower\": 0.0001, \"upper\": 0.01}\n",
    "    }\n",
    "    return config_space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80156c87-10b9-4728-9fba-43fb0346ec63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def sample_hyperparameters(config_space):\n",
    "    sampled_config = {}\n",
    "    for param, details in config_space.items():\n",
    "        if details[\"type\"] == \"float\":\n",
    "            sampled_config[param] = random.uniform(details[\"lower\"], details[\"upper\"])\n",
    "        elif details[\"type\"] == \"categorical\":\n",
    "            sampled_config[param] = random.choice(details[\"choices\"])\n",
    "    return sampled_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d354d37-9ca9-4d1c-a935-fb78a0ec45c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled Hyperparameters: {'dropout': 0.2907754557882343, 'num_filters': 64, 'lr': 0.001997670302093464}\n"
     ]
    }
   ],
   "source": [
    "config_space = get_configspace()\n",
    "sampled_config = sample_hyperparameters(config_space)\n",
    "print(\"Sampled Hyperparameters:\", sampled_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0dc1d3d3-7023-4686-ab66-fbe9535cece0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:25:52 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x1a847eb50; connected IPv4; for PYRO:Pyro.NameServer@localhost:52997>\n",
      "11:25:52 WORKER: No dispatcher found. Waiting for one to initiate contact.\n",
      "11:25:52 WORKER: start listening for jobs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration space object:\n",
      "  Hyperparameters:\n",
      "    dropout, Type: UniformFloat, Range: [0.2, 0.5], Default: 0.35\n",
      "    lr, Type: UniformFloat, Range: [0.0001, 0.01], Default: 0.00505\n",
      "    num_filters, Type: Categorical, Choices: {16, 32, 64}, Default: 16\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'get_hyperparameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(CNNWorker.get_configspace())\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Run BOHB Optimization\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m bohb = \u001b[43mBOHB\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfigspace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msampled_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnameserver\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlocalhost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnameserver_port\u001b[49m\u001b[43m=\u001b[49m\u001b[43mNS\u001b[49m\u001b[43m.\u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmin_budget\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Minimum epochs per trial\u001b[39;49;00m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_budget\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Maximum epochs per trial\u001b[39;49;00m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# result_logger=result_logger\u001b[39;49;00m\n\u001b[32m     24\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m res = bohb.run(n_iterations= \u001b[38;5;28mint\u001b[39m(\u001b[32m2\u001b[39m))  \u001b[38;5;66;03m# Number of trials\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# # Shutdown Nameserver and Worker\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# bohb.shutdown(shutdown_workers=True)\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# NS.shutdown()\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# print(f\"\\n🔹 Best Model Config: {res.get_id2config_mapping()[best_config]['config']}\")\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# print(f\"✅ Best Accuracy: {best_accuracy:.2f}%\")\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/hpbandster/optimizers/bohb.py:85\u001b[39m, in \u001b[36mBOHB.__init__\u001b[39m\u001b[34m(self, configspace, eta, min_budget, max_budget, min_points_in_model, top_n_percent, num_samples, random_fraction, bandwidth_factor, min_bandwidth, **kwargs)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m configspace \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     81\u001b[39m \t\u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mYou have to provide a valid CofigSpace object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m cg = \u001b[43mCG_BOHB\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfigspace\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfigspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m\t\t\t\u001b[49m\u001b[43mmin_points_in_model\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_points_in_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m\t\t\t\u001b[49m\u001b[43mtop_n_percent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtop_n_percent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m\t\t\t\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m\t\t\t\u001b[49m\u001b[43mrandom_fraction\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_fraction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m\t\t\t\u001b[49m\u001b[43mbandwidth_factor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbandwidth_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m\t\t\t\u001b[49m\u001b[43mmin_bandwidth\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_bandwidth\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m\t\t\t\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(config_generator=cg, **kwargs)\n\u001b[32m     96\u001b[39m \u001b[38;5;66;03m# Hyperband related stuff\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/hpbandster/optimizers/config_generators/bohb.py:56\u001b[39m, in \u001b[36mBOHB.__init__\u001b[39m\u001b[34m(self, configspace, min_points_in_model, top_n_percent, num_samples, random_fraction, bandwidth_factor, min_bandwidth, **kwargs)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;28mself\u001b[39m.min_points_in_model = min_points_in_model\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m min_points_in_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m \t\u001b[38;5;28mself\u001b[39m.min_points_in_model = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfigspace\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_hyperparameters\u001b[49m())+\u001b[32m1\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.min_points_in_model < \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.configspace.get_hyperparameters())+\u001b[32m1\u001b[39m:\n\u001b[32m     59\u001b[39m \t\u001b[38;5;28mself\u001b[39m.logger.warning(\u001b[33m'\u001b[39m\u001b[33mInvalid min_points_in_model value. Setting it to \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[33m'\u001b[39m%(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.configspace.get_hyperparameters())+\u001b[32m1\u001b[39m))\n",
      "\u001b[31mAttributeError\u001b[39m: 'dict' object has no attribute 'get_hyperparameters'"
     ]
    }
   ],
   "source": [
    "# Set up BOHB optimization\n",
    "run_id = \"bohb_hpo\"\n",
    "# result_logger = hpres.json_result_logger(directory=\"./bohb_results\", overwrite=True)\n",
    "\n",
    "# Start Nameserver for BOHB\n",
    "NS = hpns.NameServer(run_id=run_id, host=\"localhost\", port=0)\n",
    "NS.start()\n",
    "\n",
    "# Start BOHB Worker\n",
    "worker = CNNWorker(run_id=run_id, dataset=dataset, nameserver=\"localhost\", nameserver_port=NS.port)\n",
    "worker.run(background=True)\n",
    "\n",
    "print(CNNWorker.get_configspace())\n",
    "\n",
    "# Run BOHB Optimization\n",
    "bohb = BOHB(\n",
    "    configspace=sampled_config,\n",
    "    run_id=run_id,\n",
    "    nameserver=\"localhost\",\n",
    "    nameserver_port=NS.port,\n",
    "    min_budget= int(1),  # Minimum epochs per trial\n",
    "    max_budget= int(5)  # Maximum epochs per trial\n",
    "    # result_logger=result_logger\n",
    ")\n",
    "\n",
    "res = bohb.run(n_iterations= int(2))  # Number of trials\n",
    "\n",
    "# # Shutdown Nameserver and Worker\n",
    "# bohb.shutdown(shutdown_workers=True)\n",
    "# NS.shutdown()\n",
    "\n",
    "# # Get Best Hyperparameters\n",
    "# best_config = res.get_incumbent_id()\n",
    "# best_accuracy = -res.get_incumbent_trajectory()[\"losses\"][-1]\n",
    "\n",
    "# print(f\"\\n🔹 Best Model Config: {res.get_id2config_mapping()[best_config]['config']}\")\n",
    "# print(f\"✅ Best Accuracy: {best_accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
