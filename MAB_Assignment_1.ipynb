{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### `---------------Mandatory Information to fill------------`"],"metadata":{"id":"j7jO_ata_tGB"}},{"cell_type":"markdown","metadata":{"id":"q5BJ7jLz7afs"},"source":["### Group ID:\n","### Group Members Name with Student ID:\n","1. Student 1\n","2. Student 2\n","3. Student 3\n","4. Student 4\n"]},{"cell_type":"markdown","source":["`-------------------Write your remarks (if any) that you want should get consider at the time of evaluation---------------`"],"metadata":{"id":"YXHhoNgkAhUg"}},{"cell_type":"markdown","source":["Remarks: ##Add here"],"metadata":{"id":"-5tK16CbA5X_"}},{"cell_type":"markdown","source":["# Background\n","\n","In the world of online streaming, user satisfaction and engagement are critical metrics for the success of a movie recommendation system. A well-designed recommendation algorithm can significantly enhance user experience by suggesting movies that align with their preferences, leading to higher platform retention and usage. Recommendation systems face the challenge of balancing exploration (discovering new movies) with exploitation (recommending known favourites) to maximize user satisfaction over time.\n"],"metadata":{"id":"5gLNZ34yH-dO"}},{"cell_type":"markdown","source":["# Scenario\n","\n","Imagine a leading online movie streaming platform, TrendMovie Inc., that aims to become the go-to destination for personalized movie recommendations. The platform features a vast collection of movies catering to diverse audiences. TrendMovie Inc. wants to optimize its recommendation strategy to deliver maximum user satisfaction while maintaining a high level of engagement. Each movie recommendation is treated as an interaction with the user, and their feedback is used to refine the recommendation strategy dynamically.\n"],"metadata":{"id":"z8nESwkOIE_u"}},{"cell_type":"markdown","source":["# Objective\n","\n","Your objective is to design and implement a recommendation system using Multi-Armed Bandit (MAB) algorithms to maximize cumulative user satisfaction. The system should dynamically allocate recommendations by learning user preferences in real-time, striking the right balance between exploration and exploitation.\n"],"metadata":{"id":"I8w5a_8g-ehV"}},{"cell_type":"markdown","source":["# Dataset\n","\n","The dataset contains user ratings for a variety of movies. Key columns in the dataset include:\n","*   **User ID:** A unique identifier for each user.\n","*   **Movie ID:** A unique identifier for each.\n","*   **Rating:** A score provided by the user for a movie (on a scale of 1 to 5).\n","*   **Timestamp:** The time when the rating was given (optional for this assignment).\n","\n","***Link for accessing dataset:***\n","https://drive.google.com/file/d/1gfobhqlVCw8Oo52JCiYpEBGhG5k7cWBr/view?usp=drive_link\n"],"metadata":{"id":"0v1QvKmDIVoe"}},{"cell_type":"markdown","source":["# Environment Details\n","\n","**Arms:** Each movie represents an \"arm\" in the MAB framework. The probability of a movie being liked by a user is initially unknown and will be estimated based on user feedback during the interactions.\n","For example:\n","\n","Arm 1: Movie A\n","\n","Arm 2: Movie B\n","\n","Arm 3: Movie C\n","\n","... and so on, for all movies in the dataset.\n","\n","**Reward Function:**\n","The reward function is defined based on user ratings:\n","\n","***Reward = 1:*** The user rates the movie high star (e.g., 4 or 5 stars).\n","\n","***Reward = 0:*** The user rates the movie low star (e.g., 1, 2, or 3 stars).\n","\n","\n","**Assumptions:**\n","\n","Run simulations for 1000 iterations for each policy\n"],"metadata":{"id":"53dVBXmoL8aF"}},{"cell_type":"markdown","source":["# Requirements and Deliverables:\n","Implement the Multi-Arm Bandit Problem for the given above scenario for all the below mentioned policy methods."],"metadata":{"id":"Z0whadvHOywr"}},{"cell_type":"markdown","source":["### Initialize constants"],"metadata":{"id":"Pck-piUAHnmp"}},{"cell_type":"code","source":["# Constants\n","\n","\n","# Initialize value function and policy"],"metadata":{"id":"dgeqZVzXHlQE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Load Dataset (0.5M)"],"metadata":{"id":"Ke_jHsCrQWG0"}},{"cell_type":"code","source":["# Code for Dataset loading and print dataset statistics\n","#-----write your code below this line---------\n","\n"],"metadata":{"id":"FSlqMVeEQa4T"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Design a Movie Environment (0.5M)"],"metadata":{"id":"HroEzPwhQkwq"}},{"cell_type":"code","source":["# Code for Dataset loading and print dataset statistics along with reward function\n","#-----write your code below this line---------\n","\n","class MovieEnvironment:\n"],"metadata":{"id":"Uc7EP7ZXQsn5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Using Random Policy (0.5M)\n","Implement a random policy for movie recommendations and print each iteration. (Mandatory)"],"metadata":{"id":"Hvbd8vPwRMBL"}},{"cell_type":"code","source":["#  run the environment with an agent that is guided by a random policy\n","#-----write your code below this line---------"],"metadata":{"id":"99WQfj3eROWc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Using Greedy Policy (1M)\n","Implement a greedy policy that always recommends the movie with the highest estimated reward and print each iteration. (Mandatory)"],"metadata":{"id":"5t2f1AlERib1"}},{"cell_type":"code","source":["#  run the environment with an agent that is guided by a greedy policy\n","#-----write your code below this line---------"],"metadata":{"id":"TbWz1eCbRib2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Using Epsilon-Greedy Policy (1.5M)\n","Implement the epsilon-greedy policy, where with probability ε you explore (recommend a random movie) and with probability (1-ε) you exploit (recommend the best-known movie). Try with ε =0.1, 0.2, 0.5 and print each iteration. What value of ε yields the best performance? (Mandatory)"],"metadata":{"id":"h65VF2JBRiph"}},{"cell_type":"code","source":["#  run the environment with an agent that is guided by a epsilon-greedy policy\n","#-----write your code below this line---------"],"metadata":{"id":"M6O9odmlRiph"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Using UCB (1M)\n","Implement the UCB algorithm for movie recommendations and print each iteration. (Mandatory)"],"metadata":{"id":"yRo-Wi17RiN2"}},{"cell_type":"code","source":["#  run the environment with an agent that is guided by a UCB\n","#-----write your code below this line---------"],"metadata":{"id":"Z8nXetCeRiN8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Plot the cumulative rewards for all policies on a single graph to compare their performance. (0.5M)"],"metadata":{"id":"y9QjCw5aIrBn"}},{"cell_type":"code","source":["#-----write your code below this line---------"],"metadata":{"id":"J_5XxqPZI2uW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Conclusion (0.5M)\n","\n","Determine which policy performs the best based on cumulative reward. Provide a concise conclusion (250 words) summarizing the decision-making process and the trade-offs between exploration and exploitation.\n","\n","`----write below this line------`"],"metadata":{"id":"xOQk0LcUImEW"}},{"cell_type":"code","source":[],"metadata":{"id":"jcdGV9-cIqli"},"execution_count":null,"outputs":[]}]}