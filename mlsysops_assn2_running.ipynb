{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a0505a39-0c51-457f-ab8a-128a3ba56dac",
      "metadata": {},
      "source": [
        "<h1>Distributed Hyperparameter Optimization (HPO) Techniques for CNN on MNIST</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "28eb5993",
      "metadata": {
        "gather": {
          "logged": 1742463752426
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.17.2)\n",
            "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: torch==2.2.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torchvision) (2.2.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch==2.2.2->torchvision) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch==2.2.2->torchvision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch==2.2.2->torchvision) (1.13.3)\n",
            "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch==2.2.2->torchvision) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch==2.2.2->torchvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch==2.2.2->torchvision) (2025.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch==2.2.2->torchvision) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy->torch==2.2.2->torchvision) (1.3.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: optuna in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.2.1)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from optuna) (1.15.1)\n",
            "Requirement already satisfied: colorlog in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from optuna) (2.0.39)\n",
            "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /Users/abhinav.gazta/Library/Python/3.11/lib/python/site-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from alembic>=1.5.0->optuna) (1.3.9)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: hpbandster in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.7.4)\n",
            "Requirement already satisfied: Pyro4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from hpbandster) (4.82)\n",
            "Requirement already satisfied: serpent in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from hpbandster) (1.41)\n",
            "Requirement already satisfied: ConfigSpace in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from hpbandster) (1.2.1)\n",
            "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from hpbandster) (1.26.4)\n",
            "Requirement already satisfied: statsmodels in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from hpbandster) (0.14.4)\n",
            "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from hpbandster) (1.15.2)\n",
            "Requirement already satisfied: netifaces in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from hpbandster) (0.11.0)\n",
            "Requirement already satisfied: pyparsing in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ConfigSpace->hpbandster) (3.2.1)\n",
            "Requirement already satisfied: typing_extensions in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ConfigSpace->hpbandster) (4.12.2)\n",
            "Requirement already satisfied: more_itertools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ConfigSpace->hpbandster) (10.6.0)\n",
            "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from statsmodels->hpbandster) (2.2.3)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from statsmodels->hpbandster) (1.0.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from statsmodels->hpbandster) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (1.17.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: ConfigSpace in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.2.1)\n",
            "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ConfigSpace) (1.26.4)\n",
            "Requirement already satisfied: pyparsing in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ConfigSpace) (3.2.1)\n",
            "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ConfigSpace) (1.15.2)\n",
            "Requirement already satisfied: typing_extensions in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ConfigSpace) (4.12.2)\n",
            "Requirement already satisfied: more_itertools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ConfigSpace) (10.6.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.2.2)\n",
            "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: torchsummary in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.5.1)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: plotly in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (6.0.1)\n",
            "Requirement already satisfied: narwhals>=1.15.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from plotly) (1.31.0)\n",
            "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from plotly) (24.2)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.10.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: ray[tune] in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.43.0)\n",
            "Requirement already satisfied: click>=7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ray[tune]) (8.1.8)\n",
            "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ray[tune]) (3.18.0)\n",
            "Requirement already satisfied: jsonschema in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ray[tune]) (4.23.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ray[tune]) (1.1.0)\n",
            "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ray[tune]) (24.2)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ray[tune]) (4.25.6)\n",
            "Requirement already satisfied: pyyaml in /Users/abhinav.gazta/Library/Python/3.11/lib/python/site-packages (from ray[tune]) (6.0.2)\n",
            "Requirement already satisfied: aiosignal in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ray[tune]) (1.3.2)\n",
            "Requirement already satisfied: frozenlist in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ray[tune]) (1.5.0)\n",
            "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ray[tune]) (2.32.3)\n",
            "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ray[tune]) (2.2.3)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ray[tune]) (2.6.2.2)\n",
            "Requirement already satisfied: pyarrow>=9.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ray[tune]) (17.0.0)\n",
            "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ray[tune]) (2025.3.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pyarrow>=9.0.0->ray[tune]) (1.26.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jsonschema->ray[tune]) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jsonschema->ray[tune]) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jsonschema->ray[tune]) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jsonschema->ray[tune]) (0.23.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas->ray[tune]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas->ray[tune]) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas->ray[tune]) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->ray[tune]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->ray[tune]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->ray[tune]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->ray[tune]) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->ray[tune]) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from referencing>=0.28.4->jsonschema->ray[tune]) (4.12.2)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: ipywidgets in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (8.1.5)\n",
            "Requirement already satisfied: comm>=0.1.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipywidgets) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipywidgets) (9.0.2)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipywidgets) (5.14.3)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.12 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipywidgets) (4.0.13)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipywidgets) (3.0.13)\n",
            "Requirement already satisfied: decorator in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
            "Requirement already satisfied: ipython-pygments-lexers in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
            "Requirement already satisfied: matplotlib-inline in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
            "Requirement already satisfied: stack_data in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
            "Requirement already satisfied: typing_extensions>=4.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: executing>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
            "Requirement already satisfied: pure-eval in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "zsh:1: no matches found: ray[default]\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement OptunaSearch (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for OptunaSearch\u001b[0m\u001b[31m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
            "Collecting ConfigSpace<0.5.0\n",
            "  Using cached configspace-0.4.21-cp311-cp311-macosx_10_9_universal2.whl\n",
            "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ConfigSpace<0.5.0) (1.26.4)\n",
            "Requirement already satisfied: cython in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ConfigSpace<0.5.0) (3.0.12)\n",
            "Requirement already satisfied: pyparsing in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ConfigSpace<0.5.0) (3.2.1)\n",
            "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ConfigSpace<0.5.0) (1.15.2)\n",
            "Installing collected packages: ConfigSpace\n",
            "  Attempting uninstall: ConfigSpace\n",
            "    Found existing installation: ConfigSpace 1.2.1\n",
            "    Uninstalling ConfigSpace-1.2.1:\n",
            "      Successfully uninstalled ConfigSpace-1.2.1\n",
            "Successfully installed ConfigSpace-0.4.21\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: ray in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.43.0)\n",
            "Requirement already satisfied: click>=7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ray) (8.1.8)\n",
            "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ray) (3.18.0)\n",
            "Requirement already satisfied: jsonschema in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ray) (4.23.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ray) (1.1.0)\n",
            "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ray) (24.2)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ray) (4.25.6)\n",
            "Requirement already satisfied: pyyaml in /Users/abhinav.gazta/Library/Python/3.11/lib/python/site-packages (from ray) (6.0.2)\n",
            "Requirement already satisfied: aiosignal in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ray) (1.3.2)\n",
            "Requirement already satisfied: frozenlist in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ray) (1.5.0)\n",
            "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ray) (2.32.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jsonschema->ray) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jsonschema->ray) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jsonschema->ray) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jsonschema->ray) (0.23.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->ray) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->ray) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->ray) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->ray) (2025.1.31)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from referencing>=0.28.4->jsonschema->ray) (4.12.2)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Name: ray\n",
            "Version: 2.43.0\n",
            "Summary: Ray provides a simple, universal API for building distributed applications.\n",
            "Home-page: https://github.com/ray-project/ray\n",
            "Author: Ray Team\n",
            "Author-email: ray-dev@googlegroups.com\n",
            "License: Apache 2.0\n",
            "Location: /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages\n",
            "Requires: aiosignal, click, filelock, frozenlist, jsonschema, msgpack, packaging, protobuf, pyyaml, requests\n",
            "Required-by: \n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: ConfigSpace in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.4.21)\n",
            "Collecting ConfigSpace\n",
            "  Using cached configspace-1.2.1-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ConfigSpace) (1.26.4)\n",
            "Requirement already satisfied: pyparsing in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ConfigSpace) (3.2.1)\n",
            "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ConfigSpace) (1.15.2)\n",
            "Requirement already satisfied: typing_extensions in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ConfigSpace) (4.12.2)\n",
            "Requirement already satisfied: more_itertools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ConfigSpace) (10.6.0)\n",
            "Installing collected packages: ConfigSpace\n",
            "  Attempting uninstall: ConfigSpace\n",
            "    Found existing installation: ConfigSpace 0.4.21\n",
            "    Uninstalling ConfigSpace-0.4.21:\n",
            "      Successfully uninstalled ConfigSpace-0.4.21\n",
            "Successfully installed ConfigSpace-1.2.1\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# TO BE DELETED ONCE COMPLETE\n",
        "%pip install torchvision\n",
        "%pip install optuna\n",
        "%pip install hpbandster\n",
        "%pip install ConfigSpace\n",
        "%pip install torch\n",
        "%pip install torchsummary\n",
        "%pip install plotly\n",
        "%pip install matplotlib\n",
        "%pip install \"ray[tune]\"\n",
        "%pip install -U ipywidgets\n",
        "%pip install \"ray[tune]\" ray[default] ray[tune-bohb]\n",
        "%pip install OptunaSearch\n",
        "%pip install 'ConfigSpace<0.5.0'\n",
        "%pip install --upgrade ray\n",
        "%pip show ray\n",
        "%pip install --upgrade ConfigSpace\n",
        "%pip install scikit-learn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40378dfd-c7b5-4245-a20b-27c4024d8854",
      "metadata": {},
      "source": [
        "<h2>1. Introduction</h2>\n",
        "\n",
        "Hyperparameter Optimization (HPO) is a critical step in deep learning model training to improve accuracy and efficiency. \n",
        "Traditional hyperparameter tuning approaches like Grid Search and Random Search are computationally expensive and inefficient. \n",
        "\n",
        "In this assignment, we compare and analyze different hyperparameter optimization strategies using distributed computing to achieve optimal hyperparameter selection efficiently."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b06f8c43-f571-4fa8-9035-b4872b8a1a31",
      "metadata": {},
      "source": [
        "<h2>2. Objectives</h2>\n",
        "\n",
        "The goal of this project is to:\n",
        "\n",
        "1. Compare multiple HPO techniques for training a Convolutional Neural Network (CNN) on the MNIST dataset.\n",
        "\n",
        "2. Evaluate these techniques based on training speed, search efficiency, accuracy, and GPU resource utilization.\n",
        "\n",
        "3. Implement real-time GPU monitoring to track memory usage and optimize resource allocation.\n",
        "\n",
        "4. Identify the most effective HPO method that balances speed, accuracy, and efficiency."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f276fa1-ccda-4598-8a80-742c5c02154f",
      "metadata": {},
      "source": [
        "<h2>3. HPO Strategies Implemented</h2>\n",
        "\n",
        "We implemented and compared four different approaches for HPO:\n",
        "\n",
        "1. Baseline (No HPO): Train the model with default hyperparameters.\n",
        "\n",
        "2. ASHA (Asynchronous Successive Halving Algorithm): Eliminates underperforming trials early to speed up training.\n",
        "\n",
        "3. BOHB (Bayesian Optimization + HyperBand): Uses Bayesian learning to intelligently select hyperparameters while efficiently allocating compute resources.\n",
        "\n",
        "4. BOHB + ASHA Hybrid: Combines BOHB’s smart selection with ASHA’s aggressive pruning for improved efficiency."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e20a9552-e528-44b8-84da-76ad306fd4c8",
      "metadata": {},
      "source": [
        "<h2>4. Implementation Details</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec1af501-d51b-40a7-828d-a80e561c4a49",
      "metadata": {},
      "source": [
        "<h2>4.1 Dataset: MNIST</h2>\n",
        "\n",
        "The MNIST dataset consists of handwritten digits (0-9).\n",
        "\n",
        "Training set: 1000 images.\n",
        "\n",
        "Test set: 1000 images.\n",
        "\n",
        "Image size: 28x28 pixels, grayscale.\n",
        "\n",
        "Output classes: 10 (digits 0-9)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8c712bed",
      "metadata": {
        "gather": {
          "logged": 1742464053463
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-20 17:45:20.394028: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import psutil\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "import optuna\n",
        "from optuna.pruners import SuccessiveHalvingPruner\n",
        "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
        "\n",
        "import ray\n",
        "from ray import tune\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "\n",
        "import ConfigSpace as CS\n",
        "import hpbandster.core.nameserver as hpns\n",
        "import hpbandster.core.result as hpres\n",
        "from hpbandster.optimizers.bohb import BOHB\n",
        "from hpbandster.core.worker import Worker\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import ssl\n",
        "\n",
        "ssl._create_default_https_context = ssl._create_unverified_context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c9c1806f-471a-46b3-bc51-4c009c826047",
      "metadata": {
        "gather": {
          "logged": 1742464724357
        }
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import numpy as np\n",
        "\n",
        "# Transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Load full MNIST dataset\n",
        "full_trainset = torchvision.datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "full_testset = torchvision.datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "# Select indices for train and test sets (use all training data)\n",
        "# Select 1000 random indices for train and test sets\n",
        "train_indices = np.random.choice(len(full_trainset), 10000, replace=False)\n",
        "test_indices = np.random.choice(len(full_testset), 10000, replace=False)\n",
        "\n",
        "# Create subsets of MNIST\n",
        "trainset = Subset(full_trainset, train_indices)\n",
        "testset = Subset(full_testset, test_indices)\n",
        "\n",
        "# Create DataLoaders\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "testloader = DataLoader(testset, batch_size=64, shuffle=False)\n",
        "\n",
        "dataset = (trainloader, testloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fac9196b-0d2d-43cd-85fe-4a1a4ba4aa7f",
      "metadata": {},
      "source": [
        "<h2>4.2 Model: CNN Architecture</h2>\n",
        "\n",
        "The CNN model used for training consists of:\n",
        "\n",
        "1. Two convolutional layers with ReLU activation.\n",
        "\n",
        "2. Max-pooling layers for feature down-sampling.\n",
        "\n",
        "3. Fully connected layers with a dropout layer.\n",
        "\n",
        "4. Softmax activation for classification.\n",
        "\n",
        "<b>Hyperparameters Considered</b>\n",
        "\n",
        "Learning Rate - 1e-4 to 1e-2 (log scale)\n",
        "\n",
        "Dropout Rate - 0.2 to 0.5\n",
        "\n",
        "Number of Filters - 16, 32, 64\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3ddb55b1-1211-487b-878a-cafaef7b7b46",
      "metadata": {
        "gather": {
          "logged": 1742464141787
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "# CNN Model for MNIST\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, dropout_rate=0.5, num_filters=32):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, num_filters, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(num_filters, num_filters * 2, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(num_filters * 2 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fabadb6d-8c84-44e4-a84f-0f29d235a66e",
      "metadata": {},
      "source": [
        "<h2>4.3 GPU Monitoring & Resource Utilization Tracking</h2>\n",
        "\n",
        "We implemented real-time GPU monitoring using PyTorch’s memory allocation tracking.\n",
        "\n",
        "GPU usage was recorded at each training epoch.\n",
        "\n",
        "This allowed us to compare memory efficiency across different HPO techniques."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "f23cea0c-590e-4a5e-8742-dc0766bc902c",
      "metadata": {
        "gather": {
          "logged": 1742464145540
        }
      },
      "outputs": [],
      "source": [
        "# function for logging GPU / CPU tracking...\n",
        "def log_memory_usage(stage=\"\"):\n",
        "    ram_usage = psutil.virtual_memory().used / (1024 ** 2)  # Convert to MB\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "        torch.cuda.empty_cache()\n",
        "        gpu_usage = torch.cuda.memory_allocated(device) / (1024 ** 2)\n",
        "    elif torch.backends.mps.is_available():\n",
        "        device = torch.device(\"mps\")\n",
        "        torch.mps.empty_cache()\n",
        "        gpu_usage = \"MPS does not expose memory tracking\"\n",
        "    else:\n",
        "        gpu_usage = \"No GPU available\"\n",
        "    return ram_usage, gpu_usage\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3034e26-fe0d-454d-afb6-fe1023814bb7",
      "metadata": {},
      "source": [
        "<h2>5. Comparison of HPO Approaches</h2>\n",
        "\n",
        "1. Training Speed\n",
        "2. Model Accuracy\n",
        "3. GPU Memory Utilization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6e5b13a-4008-4923-863e-9a3beaba337c",
      "metadata": {},
      "source": [
        "<h2>5.1 Baseline Model (No HPO)</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "c4aa2ddb-c1fb-415c-babc-a7eca64f45a7",
      "metadata": {
        "gather": {
          "logged": 1742464752396
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Baseline Accuracy: 96.59%, Training Time: 14.33s, Avg CPU RAM Usage: 4210.89 MB, GPU Usage: 41.8486328125 MB\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import time\n",
        "import psutil\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Train Baseline Model (Without HPO) with GPU Logging\n",
        "def train_baseline():\n",
        "    writer = SummaryWriter(log_dir=\"./logs/baseline\")\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "    model = CNN().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    \n",
        "    start_time = time.time()\n",
        "    memory_logs = []\n",
        "    gpu_logs = []\n",
        "\n",
        "    for epoch in range(5):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "        ram_usage, gpu_usage = log_memory_usage(\"Baseline\")\n",
        "        memory_logs.append(ram_usage)\n",
        "        gpu_logs.append(gpu_usage)\n",
        "        \n",
        "        writer.add_scalar(\"Loss/train\", epoch_loss / len(trainloader), epoch)\n",
        "        writer.add_scalar(\"Memory/CPU_RAM_MB\", ram_usage, epoch)\n",
        "        if torch.cuda.is_available():\n",
        "            writer.add_scalar(\"Memory/GPU_RAM_MB\", gpu_usage, epoch)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    avg_ram_usage = sum(memory_logs) / len(memory_logs)\n",
        "    avg_gpu_usage = sum(gpu_logs[:-1]) / (len(gpu_logs) - 1) if torch.cuda.is_available() else \"GPU not available\"\n",
        "\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Baseline Accuracy: {accuracy:.2f}%, Training Time: {end_time - start_time:.2f}s, Avg CPU RAM Usage: {avg_ram_usage:.2f} MB, GPU Usage: {avg_gpu_usage} MB\")\n",
        "    writer.close()\n",
        "\n",
        "    return accuracy, end_time - start_time, avg_ram_usage, avg_gpu_usage\n",
        "\n",
        "baseline_accuracy, baseline_time, baseline_memory, baseline_gpu = train_baseline()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "b9e32f70-9e7f-439c-97bb-22b78e44208d",
      "metadata": {
        "gather": {
          "logged": 1742465486512
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-20 10:00:48,373] A new study created in memory with name: asha_hpo\n",
            "[I 2025-03-20 10:03:55,930] Trial 5 pruned. \n",
            "[I 2025-03-20 10:05:16,634] Trial 4 finished with value: 96.95 and parameters: {'dropout': 0.24783961516293096, 'num_filters': 32, 'lr': 0.0010890338483695852}. Best is trial 0 with value: 96.95.\n",
            "[I 2025-03-20 10:06:08,971] Trial 7 pruned. \n",
            "[I 2025-03-20 10:07:02,048] Trial 9 pruned. \n",
            "[I 2025-03-20 10:07:55,353] Trial 11 pruned. \n",
            "[I 2025-03-20 10:08:48,817] Trial 13 pruned. \n",
            "[I 2025-03-20 10:09:16,259] Trial 14 pruned. \n",
            "[I 2025-03-20 10:10:09,580] Trial 16 pruned. \n",
            "[I 2025-03-20 10:10:37,183] Trial 17 pruned. \n",
            "[I 2025-03-20 10:11:01,903] Trial 15 pruned. \n",
            "[I 2025-03-20 10:11:16,127] Trial 19 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 94.42%, Training Time: 133.67s, Avg CPU RAM Usage: 4204.11 MB, GPU Usage: 45.9033203125\n",
            "Accuracy: 96.95%, Training Time: 133.73s, Avg CPU RAM Usage: 4204.12 MB, GPU Usage: 46.21630859375\n",
            "Accuracy: 96.32%, Training Time: 133.73s, Avg CPU RAM Usage: 4204.11 MB, GPU Usage: 52.3802490234375\n",
            "Accuracy: 94.40%, Training Time: 133.65s, Avg CPU RAM Usage: 4202.19 MB, GPU Usage: 46.1240234375\n",
            "Accuracy: 96.95%, Training Time: 134.23s, Avg CPU RAM Usage: 4199.96 MB, GPU Usage: 46.124267578125\n",
            "Accuracy: 96.97%, Training Time: 133.76s, Avg CPU RAM Usage: 4194.03 MB, GPU Usage: 46.63330078125\n",
            "Accuracy: 97.05%, Training Time: 133.31s, Avg CPU RAM Usage: 4191.87 MB, GPU Usage: 46.364990234375\n",
            "Accuracy: 97.18%, Training Time: 133.13s, Avg CPU RAM Usage: 4197.78 MB, GPU Usage: 46.12451171875\n",
            "Accuracy: 97.39%, Training Time: 133.66s, Avg CPU RAM Usage: 4195.47 MB, GPU Usage: 46.004638671875\n",
            "\n",
            "Best Model Config: {'dropout': 0.2136591945049297, 'num_filters': 64, 'lr': 0.004820265494502213}\n",
            "Best Accuracy: 97.39%\n",
            "Best Training Time: 133.13s\n",
            "Best Avg CPU RAM Usage: 4197.78 MB\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "from optuna.pruners import SuccessiveHalvingPruner\n",
        "import multiprocessing\n",
        "import torch\n",
        "import time\n",
        "import psutil\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, dropout_rate=0.2, num_filters=16):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, num_filters, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc = nn.Linear(num_filters * 14 * 14, 10)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Train Model with ASHA HPO, Memory Logging, and TensorBoard Logging\n",
        "def train_cnn_asha(trial):\n",
        "    writer = SummaryWriter(log_dir=f\"./logs/asha_trial_{trial.number}\")\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "\n",
        "    dropout_rate = trial.suggest_float(\"dropout\", 0.2, 0.5)\n",
        "    num_filters = trial.suggest_categorical(\"num_filters\", [16, 32, 64])\n",
        "    learning_rate = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
        "\n",
        "    model = CNN(dropout_rate=dropout_rate, num_filters=num_filters).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    memory_logs = []\n",
        "    gpu_logs = []\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(5):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        ram_usage, gpu_usage = log_memory_usage(\"ASHA\")\n",
        "        memory_logs.append(ram_usage)\n",
        "        gpu_logs.append(gpu_usage)\n",
        "\n",
        "        writer.add_scalar(\"Loss/train\", epoch_loss / len(trainloader), epoch)\n",
        "        writer.add_scalar(\"Memory/CPU_RAM_MB\", ram_usage, epoch)\n",
        "        if torch.cuda.is_available():\n",
        "            writer.add_scalar(\"Memory/GPU_RAM_MB\", gpu_usage, epoch)\n",
        "\n",
        "        model.eval()\n",
        "        correct, total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in testloader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        accuracy = 100 * correct / total\n",
        "        trial.report(accuracy, epoch)\n",
        "\n",
        "        if trial.should_prune():\n",
        "            writer.close()\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    avg_ram_usage = sum(memory_logs) / len(memory_logs)\n",
        "    avg_gpu_usage = sum(gpu_logs[:-1]) / (len(gpu_logs) - 1) if torch.cuda.is_available() else \"GPU not available\"\n",
        "\n",
        "    writer.add_scalar(\"Accuracy\", accuracy)\n",
        "    writer.add_scalar(\"Training Time (s)\", end_time - start_time)\n",
        "    if torch.cuda.is_available():\n",
        "        writer.add_scalar(\"Memory/GPU_AVG_MB\", avg_gpu_usage)\n",
        "    writer.close()\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.2f}%, Training Time: {end_time - start_time:.2f}s, \"\n",
        "          f\"Avg CPU RAM Usage: {avg_ram_usage:.2f} MB, GPU Usage: {avg_gpu_usage}\")\n",
        "\n",
        "    return accuracy, end_time - start_time, avg_ram_usage, avg_gpu_usage\n",
        "\n",
        "# Store best training time & resource usage\n",
        "best_training_time = float(\"inf\")\n",
        "best_ram_usage = float(\"inf\")\n",
        "best_gpu_usage = None\n",
        "\n",
        "# Optimize parallel processing\n",
        "n_jobs = max(1, multiprocessing.cpu_count() // 2)  # Use half the available cores\n",
        "\n",
        "# Enable best GPU performance for Apple MPS\n",
        "torch.set_float32_matmul_precision('high')\n",
        "\n",
        "# Define Objective Function for Optuna\n",
        "def objective(trial):\n",
        "    global best_training_time, best_ram_usage, best_gpu_usage\n",
        "\n",
        "    accuracy, training_time, avg_ram_usage, gpu_usage = train_cnn_asha(trial)\n",
        "\n",
        "    # Track best training time & resource utilization\n",
        "    if training_time < best_training_time:\n",
        "        best_training_time = training_time\n",
        "        best_ram_usage = avg_ram_usage\n",
        "        best_gpu_usage = gpu_usage\n",
        "\n",
        "    return accuracy  # Optuna optimizes based on accuracy\n",
        "\n",
        "# Create Optuna Study with ASHA (Successive Halving)\n",
        "study = optuna.create_study(\n",
        "    study_name=\"asha_hpo\",\n",
        "    direction=\"maximize\",\n",
        "    pruner=SuccessiveHalvingPruner(),\n",
        "    sampler=optuna.samplers.TPESampler(\n",
        "        multivariate=True,\n",
        "        constant_liar=True\n",
        "    )\n",
        ")\n",
        "\n",
        "# Run Optimization (20 Trials)\n",
        "study.optimize(objective, n_trials=20, n_jobs=n_jobs) # added n_jobs\n",
        "\n",
        "# Print Best Results\n",
        "print(f\"\\nBest Model Config: {study.best_params}\")\n",
        "print(f\"Best Accuracy: {study.best_value:.2f}%\")\n",
        "print(f\"Best Training Time: {best_training_time:.2f}s\")\n",
        "print(f\"Best Avg CPU RAM Usage: {best_ram_usage:.2f} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c76ca153-a9fa-4683-80c0-b9f59093fdc0",
      "metadata": {},
      "source": [
        "<h2>5.2 ASHA HPO</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "43a251ff-f204-42d0-b1d9-ffb0235f459e",
      "metadata": {
        "gather": {
          "logged": 1742453354147
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-20 06:41:12,563] A new study created in memory with name: asha_hpo\n",
            "[I 2025-03-20 06:44:25,651] Trial 3 pruned. \n",
            "[I 2025-03-20 06:44:26,482] Trial 4 pruned. \n",
            "[I 2025-03-20 06:44:26,799] Trial 5 pruned. \n",
            "[I 2025-03-20 06:45:20,935] Trial 6 pruned. \n",
            "[I 2025-03-20 06:45:22,035] Trial 7 pruned. \n",
            "[I 2025-03-20 06:45:22,324] Trial 8 pruned. \n",
            "[I 2025-03-20 06:46:16,685] Trial 9 pruned. \n",
            "[I 2025-03-20 06:46:17,562] Trial 10 pruned. \n",
            "[I 2025-03-20 06:46:18,488] Trial 11 pruned. \n",
            "[I 2025-03-20 06:47:13,960] Trial 13 pruned. \n",
            "[I 2025-03-20 06:47:15,760] Trial 14 pruned. \n",
            "[I 2025-03-20 06:48:10,517] Trial 15 pruned. \n",
            "[I 2025-03-20 06:48:12,766] Trial 16 pruned. \n",
            "[I 2025-03-20 06:49:07,474] Trial 17 pruned. \n",
            "[I 2025-03-20 06:49:08,577] Trial 18 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 94.12%, Training Time: 138.57s, Avg CPU RAM Usage: 17585.58 MB, GPU Usage: 11760.55224609375\n",
            "Accuracy: 96.83%, Training Time: 138.75s, Avg CPU RAM Usage: 17587.96 MB, GPU Usage: 11759.0458984375\n",
            "Accuracy: 97.39%, Training Time: 142.65s, Avg CPU RAM Usage: 17582.59 MB, GPU Usage: 11759.58251953125\n",
            "\n",
            "Best Model Config: {'dropout': 0.22384388148601603, 'num_filters': 32, 'lr': 0.008830491863782234}\n",
            "Best Accuracy: 97.39%\n",
            "Best Training Time: 137.99s\n",
            "Best Avg CPU RAM Usage: 17585.49MB\n"
          ]
        }
      ],
      "source": [
        "# Train Model with ASHA HPO, Memory Logging, and TensorBoard Logging\n",
        "def train_cnn_asha(trial):\n",
        "    writer = SummaryWriter(log_dir=f\"./logs/asha_trial_{trial.number}\")\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "\n",
        "    dropout_rate = trial.suggest_float(\"dropout\", 0.2, 0.5)\n",
        "    num_filters = trial.suggest_categorical(\"num_filters\", [16, 32, 64])\n",
        "    learning_rate = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
        "\n",
        "    model = CNN(dropout_rate=dropout_rate, num_filters=num_filters).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    memory_logs = []\n",
        "    gpu_logs = []\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(5):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        ram_usage, gpu_usage = log_memory_usage(\"ASHA\")\n",
        "        memory_logs.append(ram_usage)\n",
        "        gpu_logs.append(gpu_usage)\n",
        "\n",
        "        writer.add_scalar(\"Loss/train\", epoch_loss / len(trainloader), epoch)\n",
        "        writer.add_scalar(\"Memory/CPU_RAM_MB\", ram_usage, epoch)\n",
        "        if torch.cuda.is_available():\n",
        "            writer.add_scalar(\"Memory/GPU_RAM_MB\", gpu_usage, epoch)\n",
        "\n",
        "        model.eval()\n",
        "        correct, total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in testloader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        accuracy = 100 * correct / total\n",
        "        trial.report(accuracy, epoch)\n",
        "\n",
        "        if trial.should_prune():\n",
        "            writer.close()\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    avg_ram_usage = sum(memory_logs) / len(memory_logs)\n",
        "    avg_gpu_usage = sum(gpu_logs[:-1]) / (len(gpu_logs) - 1) if torch.cuda.is_available() else \"GPU not available\"\n",
        "\n",
        "    writer.add_scalar(\"Accuracy\", accuracy)\n",
        "    writer.add_scalar(\"Training Time (s)\", end_time - start_time)\n",
        "    if torch.cuda.is_available():\n",
        "        writer.add_scalar(\"Memory/GPU_AVG_MB\", avg_gpu_usage)\n",
        "    writer.close()\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.2f}%, Training Time: {end_time - start_time:.2f}s, \"\n",
        "          f\"Avg CPU RAM Usage: {avg_ram_usage:.2f} MB, GPU Usage: {avg_gpu_usage}\")\n",
        "\n",
        "    return accuracy, end_time - start_time, avg_ram_usage, avg_gpu_usage\n",
        "\n",
        "# Store best training time & resource usage\n",
        "best_training_time = float(\"inf\")\n",
        "best_ram_usage = float(\"inf\")\n",
        "best_gpu_usage = None\n",
        "\n",
        "# Optimize parallel processing\n",
        "n_jobs = max(1, multiprocessing.cpu_count() // 2)  # Use half the available cores\n",
        "\n",
        "# Enable best GPU performance for Apple MPS\n",
        "torch.set_float32_matmul_precision('high')\n",
        "\n",
        "# Define Objective Function for Optuna\n",
        "def objective(trial):\n",
        "    global best_training_time, best_ram_usage, best_gpu_usage\n",
        "\n",
        "    accuracy, training_time, avg_ram_usage, gpu_usage = train_cnn_asha(trial)\n",
        "\n",
        "    # Track best training time & resource utilization\n",
        "    if training_time < best_training_time:\n",
        "        best_training_time = training_time\n",
        "        best_ram_usage = avg_ram_usage\n",
        "        best_gpu_usage = gpu_usage\n",
        "\n",
        "    return accuracy  # Optuna optimizes based on accuracy\n",
        "\n",
        "# Create Optuna Study with ASHA (Successive Halving)\n",
        "study = optuna.create_study(\n",
        "    study_name=\"asha_hpo\",\n",
        "    direction=\"maximize\",\n",
        "    pruner=SuccessiveHalvingPruner(),\n",
        "    sampler=optuna.samplers.TPESampler(\n",
        "        multivariate=True,\n",
        "        constant_liar=True\n",
        "    )\n",
        ")\n",
        "\n",
        "# Run Optimization (20 Trials)\n",
        "study.optimize(objective, n_trials=20, n_jobs=n_jobs) # added n_jobs\n",
        "\n",
        "# Print Best Results\n",
        "print(f\"\\nBest Model Config: {study.best_params}\")\n",
        "print(f\"Best Accuracy: {study.best_value:.2f}%\")\n",
        "print(f\"Best Training Time: {best_training_time:.2f}s\")\n",
        "print(f\"Best Avg CPU RAM Usage: {best_ram_usage:.2f}MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12941056-72c2-46ac-b38f-057a3fe57c32",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "OPTUNA STUDY .\n",
        "Optuna Study with ASHA (Successive Halving)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "33ee6251-1944-46b2-ac6e-2bb314f192d7",
      "metadata": {
        "gather": {
          "logged": 1742455432078
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/jupyter_env/lib/python3.10/site-packages/optuna/_experimental.py:31: ExperimentalWarning:\n",
            "\n",
            "Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
            "\n",
            "/anaconda/envs/jupyter_env/lib/python3.10/site-packages/optuna/_experimental.py:31: ExperimentalWarning:\n",
            "\n",
            "Argument ``constant_liar`` is an experimental feature. The interface can change in the future.\n",
            "\n",
            "[I 2025-03-20 07:17:37,196] A new study created in memory with name: asha_hpo\n",
            "[I 2025-03-20 07:18:47,831] Trial 2 pruned. \n",
            "[I 2025-03-20 07:19:27,662] Trial 4 pruned. \n",
            "[I 2025-03-20 07:19:55,833] Trial 5 finished with value: 97.1 and parameters: {'dropout': 0.2591846152128633, 'num_filters': 64, 'lr': 0.0028806532818027863}. Best is trial 5 with value: 97.1.\n",
            "[I 2025-03-20 07:20:07,065] Trial 6 pruned. \n",
            "[I 2025-03-20 07:20:18,522] Trial 7 pruned. \n",
            "[I 2025-03-20 07:20:30,563] Trial 8 pruned. \n",
            "[I 2025-03-20 07:20:42,338] Trial 9 pruned. \n",
            "[I 2025-03-20 07:21:11,798] Trial 10 pruned. \n",
            "[I 2025-03-20 07:21:23,121] Trial 11 pruned. \n",
            "[I 2025-03-20 07:21:52,965] Trial 12 pruned. \n",
            "[I 2025-03-20 07:22:23,656] Trial 13 pruned. \n",
            "[I 2025-03-20 07:22:35,583] Trial 14 pruned. \n",
            "[I 2025-03-20 07:22:47,495] Trial 15 pruned. \n",
            "[I 2025-03-20 07:22:59,892] Trial 16 pruned. \n",
            "[I 2025-03-20 07:23:11,497] Trial 17 pruned. \n",
            "[I 2025-03-20 07:23:22,552] Trial 18 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 92.67%, Training Time: 29.09s, Avg CPU RAM Usage: 17603.83 MB, GPU Usage: 11757.201416015625\n",
            "Accuracy: 96.36%, Training Time: 29.31s, Avg CPU RAM Usage: 17610.68 MB, GPU Usage: 11757.201416015625\n",
            "Accuracy: 96.91%, Training Time: 28.43s, Avg CPU RAM Usage: 17616.26 MB, GPU Usage: 11757.738525390625\n",
            "Accuracy: 97.10%, Training Time: 28.09s, Avg CPU RAM Usage: 17604.38 MB, GPU Usage: 11758.699462890625\n",
            "\n",
            "Best Model Config: {'dropout': 0.2591846152128633, 'num_filters': 64, 'lr': 0.0028806532818027863}\n",
            "Best Accuracy: 97.10%\n",
            "Best Training Time: 28.09s\n",
            "Best Avg CPU RAM Usage: 17604.38 MB\n",
            "Best GPU Usage: 11758.699462890625\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "from optuna.pruners import SuccessiveHalvingPruner\n",
        "import multiprocessing\n",
        "\n",
        "# Store best training time & resource usage\n",
        "best_training_time = float(\"inf\")\n",
        "best_ram_usage = float(\"inf\")\n",
        "best_gpu_usage = None\n",
        "\n",
        "# Optimize parallel processing\n",
        "# n_jobs = max(1, multiprocessing.cpu_count() // 2)  # Use half the available cores\n",
        "\n",
        "# Enable best GPU performance for Apple MPS\n",
        "torch.set_float32_matmul_precision('high') \n",
        "\n",
        "# Define Objective Function for Optuna\n",
        "def objective(trial):\n",
        "    global best_training_time, best_ram_usage, best_gpu_usage\n",
        "\n",
        "    accuracy, training_time, avg_ram_usage, gpu_usage = train_cnn_asha(trial)  # Now returns more metrics\n",
        "\n",
        "    # Track best training time & resource utilization\n",
        "    if training_time < best_training_time:\n",
        "        best_training_time = training_time\n",
        "        best_ram_usage = avg_ram_usage\n",
        "        best_gpu_usage = gpu_usage\n",
        "\n",
        "    return accuracy  # Optuna optimizes based on accuracy\n",
        "\n",
        "# Create Optuna Study with ASHA (Successive Halving)\n",
        "study = optuna.create_study(\n",
        "    study_name=\"asha_hpo\",\n",
        "    direction=\"maximize\",  # We want to maximize accuracy\n",
        "    pruner=SuccessiveHalvingPruner(),  # ASHA Pruning\n",
        "    sampler=optuna.samplers.TPESampler(\n",
        "        multivariate=True,  # Optimizes multiple parameters together\n",
        "        constant_liar=True  # Avoids redundant evaluations\n",
        "    )\n",
        ")\n",
        "\n",
        "# Run Optimization (20 Trials)\n",
        "study.optimize(objective, n_trials=20)\n",
        "\n",
        "# Print Best Results\n",
        "print(f\"\\nBest Model Config: {study.best_params}\")\n",
        "print(f\"Best Accuracy: {study.best_value:.2f}%\")\n",
        "print(f\"Best Training Time: {best_training_time:.2f}s\")\n",
        "print(f\"Best Avg CPU RAM Usage: {best_ram_usage:.2f} MB\")\n",
        "print(f\"Best GPU Usage: {best_gpu_usage}\")\n",
        "\n",
        "# plotts..\n",
        "# Plot optimization history\n",
        "optimization_history_fig = plot_optimization_history(study)\n",
        "optimization_history_fig.show()\n",
        "\n",
        "# Plot parameter importances\n",
        "param_importances_fig = plot_param_importances(study)\n",
        "param_importances_fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04df7c74",
      "metadata": {},
      "source": [
        "## Distributed Hyperparameter Optimization (HPO) with Ray Tune\n",
        "\n",
        "To improve the efficiency of hyperparameter tuning, we implement a distributed HPO strategy using Ray Tune. Ray Tune supports various search algorithms, including Bayesian Optimization, Genetic Algorithms, and Asynchronous Successive Halving (ASHA), making it ideal for large-scale HPO tasks.\n",
        "\n",
        "### 1. Search Space Definition\n",
        "\n",
        "We define the search space for a deep learning model as follows:\n",
        "\n",
        "* **Learning rate:** Log-uniform distribution between 1e-5 and 1e-1.\n",
        "* **Batch size:** Categorical values [16, 32, 64].\n",
        "* **Dropout rate:** Uniform distribution between 0.1 and 0.5.\n",
        "* **Number of layers:** Integer values between 2 and 5.\n",
        "\n",
        "### 2. Parallel Execution using Ray\n",
        "\n",
        "Ray Tune enables parallel trial execution across multiple nodes and GPUs:\n",
        "\n",
        "* Configure a Ray cluster for multi-node execution.\n",
        "* Utilize BOHB (Bayesian Optimization HyperBand) for sample efficiency and effective exploration.\n",
        "* Employ ASHA (Asynchronous Successive Halving) for dynamic early stopping, reducing unnecessary computation.\n",
        "\n",
        "### 3. Adaptive Scheduling and Resource Allocation\n",
        "\n",
        "Ray Tune dynamically reallocates resources to the most promising trials:\n",
        "\n",
        "* Trials demonstrating poor performance are stopped early using ASHA.\n",
        "* Bayesian models refine the search space, guiding the search towards better configurations.\n",
        "\n",
        "### 4. Implementation in Ray\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "895cfadd",
      "metadata": {
        "gather": {
          "logged": 1742456582960
        },
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "import ray\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "import numpy as np\n",
        "from ray.tune.search.optuna import OptunaSearch \n",
        "from ray import tune\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "from ray.tune.search.optuna import OptunaSearch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "ray.shutdown()\n",
        "ray.init()\n",
        "\n",
        "# Transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Load full MNIST dataset\n",
        "full_trainset = torchvision.datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "full_testset = torchvision.datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "# Select 1000 random indices for train and test sets\n",
        "train_indices = np.random.choice(len(full_trainset), 10000, replace=False)\n",
        "test_indices = np.random.choice(len(full_testset), 10000, replace=False)\n",
        "\n",
        "# Create subsets of MNIST\n",
        "trainset = Subset(full_trainset, train_indices)\n",
        "testset = Subset(full_testset, test_indices)\n",
        "\n",
        "# Loaders using Ray\n",
        "def load_data(config):\n",
        "    trainloader = DataLoader(trainset, batch_size=config[\"batch_size\"], shuffle=True)\n",
        "    testloader = DataLoader(testset, batch_size=config[\"batch_size\"], shuffle=False)\n",
        "    return trainloader, testloader\n",
        "\n",
        "\n",
        "\n",
        "# Search space\n",
        "search_space = {\n",
        "    \"lr\": tune.loguniform(1e-5, 1e-1),\n",
        "    \"batch_size\": tune.choice([16, 32, 64]),\n",
        "    \"dropout\": tune.uniform(0.1, 0.5),\n",
        "    \"num_layers\": tune.randint(2, 5)\n",
        "}\n",
        "\n",
        "# ASHA scheduler\n",
        "scheduler = ASHAScheduler(\n",
        "    max_t=10,\n",
        "    grace_period=1,\n",
        "    reduction_factor=2\n",
        ")\n",
        "\n",
        "# Optuna Search\n",
        "search_alg = OptunaSearch(\n",
        "    metric=\"loss\",\n",
        "    mode=\"min\"\n",
        ")\n",
        "\n",
        "# Build model\n",
        "def build_model(config):\n",
        "    layers = [nn.Flatten()]\n",
        "    for _ in range(config[\"num_layers\"]):\n",
        "        layers.append(nn.Linear(784, 128))\n",
        "        layers.append(nn.ReLU())\n",
        "        layers.append(nn.Dropout(config[\"dropout\"]))\n",
        "    layers.append(nn.Linear(128, 10))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "# Training function\n",
        "def train(config):\n",
        "    trainloader, testloader = load_data(config)\n",
        "    model = build_model(config)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
        "\n",
        "    for epoch in range(10):\n",
        "        model.train()\n",
        "        for inputs, labels in trainloader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in testloader:\n",
        "                outputs = model(inputs)\n",
        "                val_loss += criterion(outputs, labels).item()\n",
        "\n",
        "        tune.report(loss=val_loss / len(testloader))\n",
        "\n",
        "# Tuner configuration\n",
        "tuner = tune.Tuner(\n",
        "    train,\n",
        "    tune_config=tune.TuneConfig(\n",
        "        search_alg=search_alg,\n",
        "        scheduler=scheduler,\n",
        "        num_samples=20,\n",
        "        metric=\"loss\",\n",
        "        mode=\"min\"\n",
        "    ),\n",
        "    param_space=search_space\n",
        ")\n",
        "\n",
        "results = tuner.fit()\n",
        "\n",
        "print(\"Best hyperparameters found were: \", results.get_best_result().config)\n",
        "ray.shutdown()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22497e50",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div class=\"tuneStatus\">\n",
              "  <div style=\"display: flex;flex-direction: row\">\n",
              "    <div style=\"display: flex;flex-direction: column;\">\n",
              "      <h3>Tune Status</h3>\n",
              "      <table>\n",
              "<tbody>\n",
              "<tr><td>Current time:</td><td>2025-03-20 18:33:10</td></tr>\n",
              "<tr><td>Running for: </td><td>00:00:10.24        </td></tr>\n",
              "<tr><td>Memory:      </td><td>10.4/16.0 GiB      </td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "    </div>\n",
              "    <div class=\"vDivider\"></div>\n",
              "    <div class=\"systemInfo\">\n",
              "      <h3>System Info</h3>\n",
              "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1.883157154557052<br>Logical resource usage: 3.0/12 CPUs, 0/0 GPUs\n",
              "    </div>\n",
              "    \n",
              "  </div>\n",
              "  <div class=\"hDivider\"></div>\n",
              "  <div class=\"trialStatus\">\n",
              "    <h3>Trial Status</h3>\n",
              "    <table>\n",
              "<thead>\n",
              "<tr><th>Trial name    </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  num_layers</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   loss</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_5a9f8023</td><td>RUNNING </td><td>127.0.0.1:47964</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.408394</td><td style=\"text-align: right;\">0.010291   </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.30102</td><td style=\"text-align: right;\">1.88316</td></tr>\n",
              "<tr><td>train_4212f678</td><td>RUNNING </td><td>127.0.0.1:47965</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\"> 0.349154</td><td style=\"text-align: right;\">0.000226136</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td></tr>\n",
              "<tr><td>train_b94a048c</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\"> 0.384521</td><td style=\"text-align: right;\">0.000277304</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "  </div>\n",
              "</div>\n",
              "<style>\n",
              ".tuneStatus {\n",
              "  color: var(--jp-ui-font-color1);\n",
              "}\n",
              ".tuneStatus .systemInfo {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              ".tuneStatus td {\n",
              "  white-space: nowrap;\n",
              "}\n",
              ".tuneStatus .trialStatus {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              ".tuneStatus h3 {\n",
              "  font-weight: bold;\n",
              "}\n",
              ".tuneStatus .hDivider {\n",
              "  border-bottom-width: var(--jp-border-width);\n",
              "  border-bottom-color: var(--jp-border-color0);\n",
              "  border-bottom-style: solid;\n",
              "}\n",
              ".tuneStatus .vDivider {\n",
              "  border-left-width: var(--jp-border-width);\n",
              "  border-left-color: var(--jp-border-color0);\n",
              "  border-left-style: solid;\n",
              "  margin: 0.5em 1em 0.5em 1em;\n",
              "}\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import ray\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "import numpy as np\n",
        "from ray.tune.search.optuna import OptunaSearch\n",
        "from ray import tune\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from ray.air import session\n",
        "from ray.train import Checkpoint\n",
        "\n",
        "\n",
        "ray.shutdown()\n",
        "if not ray.is_initialized():\n",
        "    ray.init()\n",
        "\n",
        "# Transformations\n",
        "# Transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Load full MNIST dataset\n",
        "full_trainset = torchvision.datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "full_testset = torchvision.datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "# Select 10000 random indices for train and test sets\n",
        "train_indices = np.random.choice(len(full_trainset), 10000, replace=False)\n",
        "test_indices = np.random.choice(len(full_testset), 10000, replace=False)\n",
        "\n",
        "# Create subsets of MNIST\n",
        "trainset = Subset(full_trainset, train_indices)\n",
        "testset = Subset(full_testset, test_indices)\n",
        "\n",
        "# Place datasets in Ray's object store\n",
        "trainset_ref = ray.put(trainset)\n",
        "testset_ref = ray.put(testset)\n",
        "\n",
        "# Loaders using Ray\n",
        "def load_data(config, trainset_ref, testset_ref):\n",
        "    trainset = ray.get(trainset_ref)\n",
        "    testset = ray.get(testset_ref)\n",
        "    trainloader = DataLoader(trainset, batch_size=config[\"batch_size\"], shuffle=True)\n",
        "    testloader = DataLoader(testset, batch_size=config[\"batch_size\"], shuffle=False)\n",
        "    return trainloader, testloader\n",
        "\n",
        "# Search space\n",
        "search_space = {\n",
        "    \"lr\": tune.loguniform(1e-5, 1e-1),\n",
        "    \"batch_size\": tune.choice([16, 32, 64]),\n",
        "    \"dropout\": tune.uniform(0.1, 0.5),\n",
        "    \"num_layers\": tune.randint(2, 5)\n",
        "}\n",
        "\n",
        "# ASHA scheduler\n",
        "scheduler = ASHAScheduler(\n",
        "    max_t=10,\n",
        "    grace_period=1,\n",
        "    reduction_factor=2\n",
        ")\n",
        "\n",
        "# Optuna Search\n",
        "search_alg = OptunaSearch(\n",
        "    metric=\"loss\",\n",
        "    mode=\"min\"\n",
        ")\n",
        "\n",
        "\n",
        "def build_model(config):\n",
        "    layers = [nn.Flatten()]\n",
        "    layers.append(nn.Linear(784, 128))\n",
        "    layers.append(nn.ReLU())\n",
        "    layers.append(nn.Dropout(config[\"dropout\"]))\n",
        "    \n",
        "    for _ in range(config[\"num_layers\"] - 1):  # Subsequent layers take input size 128\n",
        "        layers.append(nn.Linear(128, 128))\n",
        "        layers.append(nn.ReLU())\n",
        "        layers.append(nn.Dropout(config[\"dropout\"]))\n",
        "\n",
        "    layers.append(nn.Linear(128, 10))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "\n",
        "# Training function\n",
        "def train(config):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Determine device\n",
        "    trainloader, testloader = load_data(config, trainset_ref, testset_ref)  # Load data with ref\n",
        "    model = build_model(config).to(device)  # Model to device\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
        "\n",
        "    for epoch in range(10):\n",
        "        model.train()\n",
        "        for inputs, labels in trainloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            # inputs = inputs.view(inputs.size(0), -1)  # Ensure flattening - Not needed now!\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in testloader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                # inputs = inputs.view(inputs.size(0), -1)  # Ensure flattening - Not needed now!\n",
        "                outputs = model(inputs)\n",
        "                val_loss_batch = criterion(outputs, labels)\n",
        "                val_loss += val_loss_batch.item()\n",
        "\n",
        "        tune.report(\n",
        "            metrics={\"loss\": val_loss / len(testloader)}\n",
        "        )\n",
        "\n",
        "# Tuner configuration\n",
        "tuner = tune.Tuner(\n",
        "    tune.with_resources(\n",
        "        train,\n",
        "        resources={\"cpu\": 1, \"gpu\": 0}  # Adjust resources as needed\n",
        "    ),\n",
        "    tune_config=tune.TuneConfig(\n",
        "        search_alg=search_alg,\n",
        "        scheduler=scheduler,\n",
        "        num_samples=20,\n",
        "        metric=\"loss\",\n",
        "        mode=\"min\"\n",
        "    ),\n",
        "    param_space=search_space\n",
        ")\n",
        "\n",
        "results = tuner.fit()\n",
        "\n",
        "print(\"Best hyperparameters found were: \", results.get_best_result().config)\n",
        "ray.shutdown()"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
